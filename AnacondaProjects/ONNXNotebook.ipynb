{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####$ ONNX-based recognizers $####\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jan 30 21:29:02 2022\n",
    "\n",
    "@author: KoRiF\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "class ONNXMNIST_Recognizer:\n",
    "    def __init__(self, directory):\n",
    "        self.path_to_model = directory\n",
    "        self.model_filename = os.path.join(self.path_to_model, 'model.onnx' )\n",
    "        # onnx_model is an in-memory ModelProto\n",
    "        self.onnx_model = onnx.load(self.model_filename)\n",
    "        return\n",
    "\n",
    "    def image2input(self, image):\n",
    "        import cv2\n",
    "        if isinstance(image, str):\n",
    "            image = cv2.imread(image) #'input.png'\n",
    "        elif not isinstance(image, np.ndarray):\n",
    "            image = np.array(image)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.resize(gray, (28,28)).astype(np.float32)/255\n",
    "        return np.reshape(gray, (1,1,28,28))\n",
    "\n",
    "    def run_session(self, model_inputs):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def recognize(self, picture_data):\n",
    "        from io import BytesIO\n",
    "        imagedata = BytesIO(bytes(picture_data))\n",
    "\n",
    "        from PIL import Image\n",
    "        img = Image.open(imagedata)\n",
    "        img.show()\n",
    "\n",
    "        img = self.image2input(img)\n",
    "\n",
    "        inputs = [img]\n",
    "\n",
    "        outputs = self.run_session(inputs)\n",
    "        print(outputs)\n",
    "        print( \"recognized as: \", np.argmax(outputs) )\n",
    "        return int(np.argmax(outputs))\n",
    "\n",
    "    def selfdiagnostic(self):\n",
    "        from onnx import numpy_helper\n",
    "        test_data_dir = 'test_data_set_{ix}'\n",
    "        test_num = len(glob.glob(os.path.join(self.path_to_model, test_data_dir.format(ix='*'))))\n",
    "\n",
    "        for no in range(test_num):\n",
    "            print('------------------------------------------------------\\n')\n",
    "\n",
    "            test_data_path = os.path.join(self.path_to_model, test_data_dir.format(ix=no))\n",
    "            print('Experiment for dataset from \"{folder}\"'.format(folder=test_data_path))\n",
    "\n",
    "            # Load inputs\n",
    "            inputs = []\n",
    "            inputs_num = len(glob.glob(os.path.join(test_data_path, 'input_*.pb')))\n",
    "            for i in range(inputs_num):\n",
    "                input_file = os.path.join(test_data_path, 'input_{}.pb'.format(i))\n",
    "                tensor = onnx.TensorProto()\n",
    "                with open(input_file, 'rb') as f:\n",
    "                    tensor.ParseFromString(f.read())\n",
    "                inputs.append(numpy_helper.to_array(tensor))\n",
    "\n",
    "            # Load reference outputs\n",
    "            ref_outputs = []\n",
    "            ref_outputs_num = len(glob.glob(os.path.join(test_data_path, 'output_*.pb')))\n",
    "            for i in range(ref_outputs_num):\n",
    "                output_file = os.path.join(test_data_path, 'output_{}.pb'.format(i))\n",
    "                tensor = onnx.TensorProto()\n",
    "                with open(output_file, 'rb') as f:\n",
    "                    tensor.ParseFromString(f.read())\n",
    "                ref_outputs.append(numpy_helper.to_array(tensor))\n",
    "\n",
    "            # Run the model on the backend\n",
    "\n",
    "            #outputs = list(backend.run_model(model, inputs))\n",
    "            outputs = self.run_session(inputs)\n",
    "\n",
    "\n",
    "            # Compare the results with reference outputs.\n",
    "            for ref_o, o in zip(ref_outputs, outputs):\n",
    "                print(\"result:\", o)\n",
    "                print(\"reference output:\", ref_o)\n",
    "                np.testing.assert_almost_equal(ref_o, o, 0)\n",
    "            print( np.argmax(ref_outputs), \"recognized as: \", np.argmax(outputs) )\n",
    "            return\n",
    "\n",
    "    def createRecognizer(recognizer_name, directory):\n",
    "        if recognizer_name == 'TF':\n",
    "            recognizer = TensorFlowONNXMNIST_Recognizer(directory)\n",
    "        #elif ... - more ONNX-compatible ML library options \n",
    "        else:\n",
    "            recognizer = RuntimeONNXMNIST_Recognizer(directory)\n",
    "        return recognizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RuntimeONNXMNIST_Recognizer(ONNXMNIST_Recognizer):\n",
    "    def run_session(self, model_inputs):\n",
    "        from onnxruntime import InferenceSession\n",
    "        sess = InferenceSession(self.onnx_model.SerializeToString())\n",
    "        return sess.run(None, {'Input3' : model_inputs[0]})\n",
    "\n",
    "\n",
    "class TensorFlowONNXMNIST_Recognizer(ONNXMNIST_Recognizer):\n",
    "    def run_session(self, model_inputs):\n",
    "        #import onnx_tf as xtf\n",
    "        from onnx_tf.backend import prepare\n",
    "        tf_rep = prepare(self.onnx_model)\n",
    "        return tf_rep.run(model_inputs)\n",
    "\n",
    "\n",
    "#class XXX_ONNXMNIST_Recognizer(ONNXMNIST_Recognizer) ...\n",
    "#... implement recognizers for all supporting ML libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016dc0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####$ application $####\n",
    "shared_data = None\n",
    "\"\"\"{\n",
    "'''$\n",
    "}\"\"\"\n",
    "%store -r shared_data\n",
    "diagnostic = shared_data['diagnostic'] if (shared_data) else True\n",
    "\"\"\"{\n",
    "$'''\n",
    "}\"\"\"\n",
    "\"\"\"%\n",
    "shared_data = dict()\n",
    "from delphi_module import delphi_form\n",
    "\n",
    "diagnostic = delphi_form.isPictureEmpty\n",
    "%\"\"\"\n",
    "\n",
    "\"\"\"{\n",
    "'''$\n",
    "}\"\"\"\n",
    "backend = shared_data['backend'] if (shared_data) else 'default' #use ONNX Runtime\n",
    "path_to_model = shared_data['path_to_model'] if (shared_data) else '?'\n",
    "\"\"\"{\n",
    "$'''\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"%\n",
    "backend = delphi_form.backendSwitchTag\n",
    "shared_data['backend'] = backend\n",
    "path_to_model = delphi_form.onnxDirectory\n",
    "shared_data['path_to_model'] = path_to_model\n",
    "%\"\"\"\n",
    "\n",
    "recognizer = ONNXMNIST_Recognizer.createRecognizer(backend, path_to_model)\n",
    "\n",
    "if diagnostic:\n",
    "    recognizer.selfdiagnostic()\n",
    "    exit\n",
    "    \n",
    "\"\"\"{\n",
    "'''$\n",
    "}\"\"\"\n",
    "mnist_digit_pict = shared_data['mnist_digit_pict']\n",
    "print(recognizer.recognize(mnist_digit_pict))\n",
    "\"\"\"{\n",
    "$'''\n",
    "}\"\"\"    \n",
    "    \n",
    "    \n",
    "\"\"\"%\n",
    "mnist_digit_pict = delphi_form.PictureData\n",
    "shared_data['mnist_digit_pict'] = mnist_digit_pict\n",
    "\n",
    "delphi_form.RecognizedValue =  recognizer.recognize(mnist_digit_pict)\n",
    "\n",
    "#%store shared_data\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "ipython.magic(\"store shared_data\")\n",
    "%\"\"\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
